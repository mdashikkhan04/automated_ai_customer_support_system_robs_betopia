# ğŸ“š **3-TIER PRIORITY RESPONSE SYSTEM - ARCHITECTURE DOCUMENTATION**

## **à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® Overview**

à¦†à¦ªà¦¨à¦¾à¦° chatbot à¦à¦–à¦¨ à¦à¦•à¦Ÿà¦¿ professionally designed **3-tier priority response system** à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡:

```
User Question
    â†“
Tier 1: Dataset (RAG) - Knowledge Base
    â”œâ”€ Semantic search with embeddings
    â”œâ”€ High-quality, curated responses
    â””â”€ If confidence â‰¥ 50% â†’ Return answer
         â†“ (if confidence < 50% or no match)
Tier 2: Web Scraping - Live Website Data
    â”œâ”€ Cached scraped data (refreshed every 6h)
    â”œâ”€ Product, FAQ, policy information
    â””â”€ If match found â†’ Return answer
         â†“ (if no good match)
Tier 3: OpenAI LLM - General ChatGPT
    â”œâ”€ General conversational responses
    â”œâ”€ Creative/open-ended questions
    â””â”€ Always provides a helpful response
         â†“
Response to User
```

---

## **Tier 1: Dataset (RAG) - à¦¸à¦°à§à¦¬à§‹à¦šà§à¦š à¦…à¦—à§à¦°à¦¾à¦§à¦¿à¦•à¦¾à¦°**

### **à¦•à§€ à¦à¦Ÿà¦¿?**
- à¦†à¦ªà¦¨à¦¾à¦° curated knowledge base (KBs) à¦¥à§‡à¦•à§‡ semantic search
- à¦¸à¦¬à¦šà§‡à¦¯à¦¼à§‡ accurate à¦à¦¬à¦‚ well-sourced à¦‰à¦¤à§à¦¤à¦°

### **à¦•à¦¿à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡?**
```python
# app/services/priority_response_service.py
def _try_dataset(user_message, intent):
    # 1. Semantic search KB using embeddings
    kb_results = kb_service.search(user_message, top_k=3)
    
    # 2. Return top result if confidence high enough
    if confidence >= 0.5:
        return KB_based_answer
```

### **à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦¡à§‡à¦Ÿà¦¾ à¦¥à¦¾à¦•à§‡?**
- `app/kb/data/complete_kb.json` - 18 comprehensive items
- `app/kb/data/faqs_comprehensive.json` - FAQ/policies
- `app/kb/data/products_comprehensive.json` - Product info

### **Example:**
```
Question: "What is HardChews?"
Tier 1 Response: "HardChews is a premium chewable dietary supplement..."
Source: complete_kb.json
Confidence: 0.92
```

---

## **Tier 2: Web Scraping - à¦®à¦¾à¦à¦¾à¦°à¦¿ à¦…à¦—à§à¦°à¦¾à¦§à¦¿à¦•à¦¾à¦°**

### **à¦•à§€ à¦à¦Ÿà¦¿?**
- Live website data à¦¥à§‡à¦•à§‡ auto-scraped information
- Cache à¦•à¦°à¦¾ locally, 24-hour TTL à¦¸à¦¹
- Product updates, policy changes capture à¦•à¦°à§‡

### **à¦•à¦¿à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡?**
```python
# app/services/enhanced_web_scraper.py
def scrape_all(force_refresh=False):
    # 1. Check if cache exists and is fresh
    if cache_valid():
        return cached_data
    
    # 2. Otherwise, scrape from website
    products = scrape_products()      # /products endpoint
    faqs = scrape_faqs()              # /faq endpoint
    policies = scrape_policies()      # /shipping, /returns, etc
    
    # 3. Cache locally for next 24 hours
    save_to_cache(products, faqs, policies)
```

### **à¦¯à§‡à¦–à¦¾à¦¨à§‡ cache à¦¥à¦¾à¦•à§‡?**
- `app/cache/scraped_data.json` - Local file-based cache
- Auto-refreshes every 6 hours (configurable)
- Manual refresh via `POST /scheduler/refresh`

### **Example:**
```
Question: "Tell me about new products"
Tier 1: No match (not in KB)
Tier 2 Response: "Based on our latest website: [Product X, Y, Z]..."
Source: web_scraper (live data)
Confidence: 0.75
```

### **Background Scheduler**
```python
# app/services/scraping_scheduler.py
scraping_scheduler = ScrapingScheduler(interval_hours=6)
scraping_scheduler.start()  # Starts on app startup

# Automatically refreshes every 6 hours
# No manual intervention needed
```

---

## **Tier 3: OpenAI LLM - à¦¸à¦°à§à¦¬à¦¨à¦¿à¦®à§à¦¨ à¦…à¦—à§à¦°à¦¾à¦§à¦¿à¦•à¦¾à¦°**

### **à¦•à§€ à¦à¦Ÿà¦¿?**
- General ChatGPT-style responses
- Creative questions à¦à¦° à¦œà¦¨à§à¦¯
- Fallback à¦¯à¦–à¦¨ Tier 1 & 2 no match à¦¦à§‡à¦¯à¦¼

### **à¦•à¦¿à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡?**
```python
# app/services/priority_response_service.py
def _try_llm(user_message, context):
    try:
        # Call OpenAI API
        reply = generate_reply(user_message, context)
        return reply
    except Exception as e:
        # LLM unavailable â†’ graceful fallback
        return "Support team will follow up..."
```

### **à¦•à¦–à¦¨ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¹à¦¯à¦¼?**
- Questions à¦¯à¦¾ KB à¦¬à¦¾ scraped data à¦¤à§‡ à¦¨à§‡à¦‡
- Creative/philosophical à¦ªà§à¦°à¦¶à§à¦¨
- General knowledge à¦ªà§à¦°à¦¶à§à¦¨

### **Example:**
```
Question: "What's a fun fact about supplements?"
Tier 1: No match
Tier 2: No match
Tier 3 Response: "Did you know that many ancient civilizations..."
Source: openai_gpt-4o-mini
Confidence: 0.80
```

---

## **System Architecture - Code Structure**

```
app/services/
â”œâ”€â”€ priority_response_service.py      â† Main orchestrator (3-tier logic)
â”œâ”€â”€ kb_service.py                     â† Tier 1: Dataset/RAG
â”œâ”€â”€ enhanced_web_scraper.py           â† Tier 2: Web scraping + caching
â”œâ”€â”€ scraping_scheduler.py             â† Background task scheduler
â”œâ”€â”€ openai_service.py                 â† Tier 3: LLM integration
â”œâ”€â”€ router_service.py                 â† Updated to use priority_service
â””â”€â”€ ...

app/cache/
â””â”€â”€ scraped_data.json                 â† Tier 2 cache file

app/kb/data/
â”œâ”€â”€ complete_kb.json                  â† Tier 1 primary data
â”œâ”€â”€ faqs_comprehensive.json
â””â”€â”€ products_comprehensive.json
```

---

## **à¦•à¦¿à¦­à¦¾à¦¬à§‡ à¦¶à§à¦°à§ à¦•à¦°à¦¬à§‡à¦¨?**

### **Step 1: Backend à¦šà¦¾à¦²à§ à¦•à¦°à§à¦¨**
```bash
cd d:/Asik/robs/automated_ai_customer_support_system_robs_betopia
venv\Scripts\activate
uvicorn app.main:app --reload
```

### **Expected Output:**
```
INFO:     Uvicorn running on http://127.0.0.1:8000
âœ… KB Service loaded 30 items
âœ… Priority System Ready:
   â€¢ Tier 1 (Dataset): 30 KB items
   â€¢ Tier 2 (Scraping): 0 cached items (first run)
   â€¢ Tier 3 (LLM): Ready
âœ… Scraping scheduler started (interval: 6h)
```

### **Step 2: System à¦Ÿà§‡à¦¸à§à¦Ÿ à¦•à¦°à§à¦¨**
```bash
python test_priority_system.py
```

### **Step 3: Frontend test à¦•à¦°à§à¦¨**
```
Open index_v2.html in browser
Send test messages:
- "What is HardChews?"
- "How do I use it?"
- "Tell me something interesting"
```

---

## **API Endpoints - à¦¨à¦¤à§à¦¨**

### **Health Check (with tier stats)**
```bash
GET /health
```
Response:
```json
{
  "status": "ok",
  "environment": "development",
  "tier_stats": {
    "tier1_dataset_items": 30,
    "tier2_scraping_items": 12,
    "tier3_llm_available": true,
    "total_data_sources": 42
  },
  "scheduler": {
    "is_running": true,
    "interval_hours": 6,
    "last_scrape_time": "2025-12-04T10:30:00",
    "next_scrape_in_seconds": 18000
  }
}
```

### **Scheduler Status**
```bash
GET /scheduler/status
```

### **Manual Scraping Refresh**
```bash
POST /scheduler/refresh?force=false
```

---

## **Configuration & Customization**

### **Tier 1: Adjust KB items**
Edit `app/kb/data/complete_kb.json`:
```json
{
  "id": "custom_item_1",
  "type": "product",
  "title": "Your Product",
  "content": "Full description...",
  "tags": ["product", "custom"]
}
```

### **Tier 2: Adjust scraping frequency**
In `app/services/scraping_scheduler.py`:
```python
scraping_scheduler = ScrapingScheduler(interval_hours=6)  # Change to 12, 24, etc
```

### **Tier 2: Adjust website URLs**
In `app/services/enhanced_web_scraper.py`:
```python
self.base_url = "https://hardchews.shop"  # Customize
policy_urls = {
    "shipping": f"{self.base_url}/shipping",
    # Add more endpoints...
}
```

### **Tier 3: Adjust LLM model**
In `app/services/openai_service.py`:
```python
completion = openai.ChatCompletion.create(
    model="gpt-4o-mini",  # Change to gpt-4, gpt-3.5-turbo, etc
    ...
)
```

---

## **Response Format - Frontend Display**

Each response includes source information:
```json
{
  "response": "ğŸ“š **From Our Knowledge Base:**\n\nHardChews is...",
  "source": "dataset",
  "confidence": 0.92,
  "intent": "general",
  "debug": {
    "message": "What is HardChews?",
    "kb_item_title": "What is HardChews?",
    "response_source": "dataset",
    "response_confidence": 0.92
  }
}
```

Frontend displays:
- ğŸ“š Tier 1 responses (blue icon)
- ğŸŒ Tier 2 responses (globe icon)
- ğŸ¤– Tier 3 responses (robot icon)

---

## **Data Flow Diagram**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Message                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Intent Detection      â”‚
          â”‚ (8 types: product,     â”‚
          â”‚  refund, shipping...)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Priority Response Service              â”‚
    â”‚   (Orchestrator)                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†™          â†“          â†˜
         Tier1      Tier2       Tier3
         (KB)    (Scraper)      (LLM)
          â†“          â†“           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Semanticâ”‚  â”‚Keyword â”‚  â”‚OpenAI  â”‚
    â”‚Search  â”‚  â”‚Search  â”‚  â”‚API     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â†“          â†“           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Select Best Response           â”‚
    â”‚  (Highest Confidence Source)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Format Response with Source     â”‚
    â”‚  (ğŸ“š/ğŸŒ/ğŸ¤– icon + content)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Return to Frontend              â”‚
    â”‚  (source, confidence, response)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **Debugging & Monitoring**

### **Enable Detailed Logs**
```python
# In app/logger.py
logger.setLevel("DEBUG")  # More detailed logs
```

### **Monitor Scraping Cache**
```python
from app.services.enhanced_web_scraper import web_scraper

cached = web_scraper.get_cached_data()
print(f"Cache size: {len(cached['products'])} products")
```

### **Check Tier Stats**
```python
from app.services.priority_response_service import priority_service

stats = priority_service.get_tier_stats()
print(stats)
# Output:
# {
#   'tier1_dataset_items': 30,
#   'tier2_scraping_items': 12,
#   'tier3_llm_available': True,
#   'total_data_sources': 42
# }
```

---

## **Performance Notes**

| Tier | Response Time | Accuracy | Best For |
|------|---------------|----------|----------|
| **1 (KB)** | < 100ms | Highest | Products, policies, FAQs |
| **2 (Scraping)** | < 500ms | High | Latest updates, site changes |
| **3 (LLM)** | 1-3s | Good | Creative, general questions |

---

## **Security Considerations**

âœ… **What's Protected:**
- API keys stored in `.env` (not in code)
- Web scraping respects rate limits (1s delay)
- Cache cleared automatically after 24h
- No PII stored in KB

âš ï¸ **What to Configure:**
- Set `allow_origins` to specific domains (production)
- Enable HTTPS/TLS on production
- Rate limit API endpoints
- Monitor for scraping failures

---

## **Next Steps**

1. âœ… Test 3-tier system locally
2. âœ… Populate more KB items (Tier 1)
3. âœ… Configure website scraping endpoints (Tier 2)
4. âœ… Get OpenAI API key for Tier 3
5. âœ… Deploy to production
6. âœ… Monitor tier usage stats

---

## **Troubleshooting**

**All questions return same answer?**
â†’ Check if `priority_service` is imported in router

**Scraping not working?**
â†’ Verify website URLs in `enhanced_web_scraper.py`

**LLM responses not good?**
â†’ Check `OPENAI_API_KEY` in `.env`

**Cache not updating?**
â†’ Check scheduler logs, manually trigger: `POST /scheduler/refresh`

---

**à¦†à¦ªà¦¨à¦¾à¦° chatbot à¦à¦–à¦¨ production-ready! ğŸš€**
